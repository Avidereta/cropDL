{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment template. \n",
    "## Note: \n",
    "template for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_name is allInoc_adadelta_unet2\n"
     ]
    }
   ],
   "source": [
    "# description = {here could be a short description of the experiment}\n",
    "\n",
    "# specific name of the experiment\n",
    "eval_name = 'allInoc_adadelta_unet2'\n",
    "\n",
    "if eval_name is None:\n",
    "    with open(path_to_dir+'eval_name.txt') as data_file:    \n",
    "        eval_name = json.load(data_file)\n",
    "print \"eval_name is\", eval_name "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The task is to predict number of lesions in the photo\n",
    "***\n",
    "### Content:\n",
    "* [Settings and experiment parameters](#sep)\n",
    "* [Load Data](#ld)\n",
    "* [Learning and visualizing results](#lav)\n",
    "* [Conclusions](#c)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Togle ON/OFF the raw code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "CODE WAS HIDDEN. TO TOGGLE ON/OFF THE RAW CODE, CLICK\n",
       "<a href=\"javascript:code_toggle()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "CODE WAS HIDDEN. TO TOGGLE ON/OFF THE RAW CODE, CLICK\n",
    "<a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"sep\"/>\n",
    "# Settings and experiment parameters\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=\"device=gpu0\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K40m (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS=\"device=gpu0\"\n",
    "\n",
    "### Check theano ####\n",
    "import theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables and paths \n",
    "* $\\textbf{Add the main directory '.../code' to   sys.path}$. \n",
    "\n",
    "The following directory was added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/slowhome/makarova/columbia/code\n"
     ]
    }
   ],
   "source": [
    "#### Add the main dir to sys ####\n",
    "\n",
    "import os, sys\n",
    "\n",
    "parentdir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
    "print parentdir\n",
    "\n",
    "sys.path.insert(0, parentdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\textbf{Put your certain values or None}$ (then use run.ipynb to set them outside).\n",
    "\n",
    "Note: In case you put None, files with parameters should be in the same directory with this .ipynb file \n",
    "(else change path_to_dir by what ever you want)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_NN = True\n",
    "\n",
    "N_FILTERS = 32\n",
    "BATCH_SIZE = 20\n",
    "N_EPOCHS = 3000\n",
    "N_BATCHES_PER_EPOCH = 10\n",
    "N_BATCHES_PER_EPOCH_valid = 10\n",
    "PATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_FILTERS =  32\n",
      "BATCH_SIZE =  20\n",
      "N_EPOCHS =  3000\n",
      "PATCH SIZE =  256\n"
     ]
    }
   ],
   "source": [
    "# Read global params from files\n",
    "import json\n",
    "\n",
    "print \"N_FILTERS = \", N_FILTERS\n",
    "print \"BATCH_SIZE = \", BATCH_SIZE\n",
    "print \"N_EPOCHS = \", N_EPOCHS\n",
    "print \"PATCH SIZE = \", PATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/makarova/columbia/data/inoculated_1/gt_img_train_ellimg_small.txt\n",
      "/home/makarova/columbia/data/inoculated_1/gt_img_valid_ellimg_small.txt\n",
      "/home/makarova/columbia/data/inoculated_1/gt_img_test_ellimg_small.txt\n",
      "/home/makarova/columbia/code/results/\n"
     ]
    }
   ],
   "source": [
    "# txt files with paths to segmentation image and input image\n",
    "txt_train = '/home/makarova/columbia/data/inoculated_1/gt_img_train_ellimg_small.txt'\n",
    "txt_valid = '/home/makarova/columbia/data/inoculated_1/gt_img_valid_ellimg_small.txt'\n",
    "txt_test = '/home/makarova/columbia/data/inoculated_1/gt_img_test_ellimg_small.txt'\n",
    "\n",
    "from config import results_path\n",
    "# path to save the results for THIS experiment\n",
    "results_eval_path = results_path + eval_name + \"/\"\n",
    "\n",
    "print txt_train\n",
    "print txt_valid\n",
    "print txt_test\n",
    "\n",
    "print results_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### IMPORTS ####\n",
    "import matplotlib\n",
    "matplotlib.use('Pdf')\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='ld'/>\n",
    "# Load Data\n",
    "</a>\n",
    "\n",
    "* Load and visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_data(txt):\n",
    "    \n",
    "    imgs = []\n",
    "    imgs_gt = []\n",
    "    \n",
    "    with open(txt, 'r') as fin:\n",
    "        lines = fin.read().splitlines()\n",
    "    for line in lines:\n",
    "        imgs.append(line.split(' ')[1]) \n",
    "        imgs_gt.append(line.split(' ')[0])\n",
    "    \n",
    "    assert(len(imgs) == len(imgs_gt))\n",
    "    imgs.sort()\n",
    "    imgs_gt.sort()\n",
    "    \n",
    "    # images are 2000 by 3000 pixels each\n",
    "    img_size = (2000, 3000)\n",
    "    data = np.zeros((len(imgs), 3, img_size[0], img_size[1]), dtype=np.uint8)\n",
    "    target = np.zeros((len(imgs), 1,  img_size[0], img_size[1]), dtype=np.uint8)\n",
    "    \n",
    "    ctr = 0\n",
    "    for i, (im, gt_im) in enumerate(zip(imgs, imgs_gt)):\n",
    "        data[ctr] = plt.imread(im).transpose((2, 0, 1))\n",
    "        img = plt.imread(gt_im,0)\n",
    "        target[ctr, 0] = img/255.\n",
    "        ctr += 1\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = load_data(txt_train)\n",
    "X_valid, Y_valid = load_data(txt_valid)\n",
    "X_test, Y_test = load_data(txt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 3, 2000, 3000)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print Y_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    }
   ],
   "source": [
    "print X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 1, 2000, 3000)\n"
     ]
    }
   ],
   "source": [
    "print Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='lav'/>\n",
    "# Learning and Visualizing\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.generator import batch_generator, random_crop_generator, threaded_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\textbf{ Characteristics of input images and the input layer}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape (2000, 3000)\n",
      "Number of channels: 3\n",
      "Input layer shape: [20, 3, 256, 256]\n"
     ]
    }
   ],
   "source": [
    "#### PREPARE DATA FOR NN ####\n",
    "\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lasagne.layers import InputLayer\n",
    "\n",
    "nmb_channels, inp_shape = X_train[0].shape[0], X_train[0].shape[1:]\n",
    "print 'Image shape', inp_shape\n",
    "print \"Number of channels:\", nmb_channels\n",
    "\n",
    "X_inp = T.tensor4('X_inp')\n",
    "X_layer = InputLayer([BATCH_SIZE, nmb_channels, PATCH_SIZE, PATCH_SIZE], \\\n",
    "                     input_var=X_inp,name='input')\n",
    "\n",
    "print \"Input layer shape:\", X_layer.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from models.unet2 import uNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import lasagne\n",
    "from models.model import Model\n",
    "from collections import OrderedDict\n",
    "from lasagne.layers import Conv2DLayer, InputLayer, ConcatLayer, Pool2DLayer, \\\n",
    "    ReshapeLayer, DimshuffleLayer, NonlinearityLayer, DropoutLayer, Upscale2DLayer\n",
    "import theano.tensor as T\n",
    "from lasagne.layers import batch_norm\n",
    "from lasagne.regularization import regularize_network_params, l2\n",
    "\n",
    "\n",
    "class uNet(Model):\n",
    "    def __init__(self,\n",
    "                 X_layer,\n",
    "                 n_filters=32,\n",
    "                 filter_size=3,\n",
    "                 name='unet',\n",
    "                 pad='same',\n",
    "                 nmb_out_classes=2,\n",
    "                 do_dropout=False):\n",
    "\n",
    "        super(uNet, self).__init__(name)\n",
    "\n",
    "        input_shape = X_layer.output_shape\n",
    "        self.build_graph(input_shape, n_filters, filter_size, nmb_out_classes, do_dropout, pad)\n",
    "        self.weights = lasagne.layers.get_all_params(self.net['output_flattened'], trainable=True)\n",
    "\n",
    "        print self.net['output_segmentation'].output_shape, self.net['output_flattened'].output_shape\n",
    "\n",
    "        self.pred_y = lasagne.layers.get_output(self.net['output_flattened'], X_layer.input_var)\n",
    "\n",
    "        self.outlayer_for_loss = self.net['output_flattened']\n",
    "        self.outlayer_seg = self.net['output_segmentation']\n",
    "\n",
    "        if isinstance(X_layer, lasagne.layers.InputLayer):\n",
    "            self.predict_fun = theano.function([X_layer.input_var], self.pred_y)\n",
    "\n",
    "    def build_graph(self, input_shape, n_filters, filter_size, nmb_out_classes, do_dropout, pad='same'):\n",
    "\n",
    "        nonlinearity = lasagne.nonlinearities.rectify\n",
    "        self.net = OrderedDict()\n",
    "        self.net['input'] = InputLayer(input_shape, name='input')\n",
    "        print \"Input: self.net['input']\", self.net['input'].output_shape\n",
    "        self.net['conv_1_1'] = Conv2DLayer(self.net['input'],\n",
    "                                            num_filters=n_filters,\n",
    "                                            filter_size=filter_size,\n",
    "                                            nonlinearity=nonlinearity,\n",
    "                                            pad=pad)\n",
    "        print \"\\nConv11: self.net['conv_1_1']\", self.net['conv_1_1'].output_shape\n",
    "        self.net['dropout1'] = DropoutLayer(self.net['conv_1_1'], p=0.2)\n",
    "        print \"Dropout1: self.net['dropout1']\", self.net['dropout1'].output_shape\n",
    "        self.net['conv_1_2'] = Conv2DLayer(batch_norm(self.net['dropout1']),\n",
    "                                            num_filters=n_filters,\n",
    "                                            filter_size=filter_size,\n",
    "                                            nonlinearity=nonlinearity,\n",
    "                                            pad=pad)\n",
    "        print \"Conv12: self.net['conv_1_2']\", self.net['conv_1_2'].output_shape\n",
    "        self.net['pool1'] = Pool2DLayer(batch_norm(self.net['conv_1_2']), 2)\n",
    "        print \"\\nPool1: self.net['pool1']\", self.net['pool1'].output_shape\n",
    "        #\n",
    "        self.net['conv_2_1'] = Conv2DLayer(batch_norm(self.net['pool1']),\n",
    "                                            num_filters=n_filters * 2,\n",
    "                                            filter_size=filter_size,\n",
    "                                            nonlinearity=nonlinearity,\n",
    "                                            pad=pad)\n",
    "        print \"Conv21: self.net['conv_2_1']\", self.net['conv_2_1'].output_shape\n",
    "        self.net['dropout2'] = DropoutLayer(batch_norm(self.net['conv_2_1']), p=0.2)\n",
    "        print \"Dropout2: self.net['dropout2']\", self.net['dropout2'].output_shape\n",
    "        self.net['conv_2_2'] = Conv2DLayer(batch_norm(self.net['dropout2']),\n",
    "                                            num_filters=n_filters * 2,\n",
    "                                            filter_size=filter_size,\n",
    "                                            nonlinearity=nonlinearity,\n",
    "                                            pad=pad)\n",
    "        print \"Conv22: self.net['conv_2_2']\", self.net['conv_2_2'].output_shape\n",
    "        self.net['pool2'] = Pool2DLayer(self.net['conv_2_2'], 2)\n",
    "        print \"\\nPool2: self.net['pool2']\", self.net['pool2'].output_shape\n",
    "        #\n",
    "        self.net['conv_3_1'] = Conv2DLayer(batch_norm(self.net['pool2']),\n",
    "                                            num_filters=n_filters * 4,\n",
    "                                            filter_size=filter_size,\n",
    "                                            nonlinearity=nonlinearity,\n",
    "                                            pad=pad)\n",
    "        print \"Conv31: self.net['conv_3_1']\", self.net['conv_3_1'].output_shape\n",
    "        self.net['dropout3'] = DropoutLayer(self.net['conv_3_1'], p=0.2)\n",
    "        print \"Dropout3: self.net['dropout3']\", self.net['dropout3'].output_shape\n",
    "        self.net['conv_3_2'] = Conv2DLayer(batch_norm(self.net['dropout3']),\n",
    "                                            num_filters=n_filters * 4,\n",
    "                                            filter_size=filter_size,\n",
    "                                            nonlinearity=nonlinearity,\n",
    "                                            pad=pad)\n",
    "        print \"Conv32: self.net['conv_3_2']\", self.net['conv_3_2'].output_shape\n",
    "\n",
    "#         self.net['pool3'] = Pool2DLayer(self.net['conv_3_2'], 2)\n",
    "#         print \"\\nPool3: self.net['pool3']\", self.net['pool3'].output_shape\n",
    "#         #\n",
    "#         self.net['conv_4_1'] = Conv2DLayer(batch_norm(self.net['pool3']),\n",
    "#                                             num_filters=n_filters * 8,\n",
    "#                                             filter_size=filter_size,\n",
    "#                                             nonlinearity=nonlinearity,\n",
    "#                                             pad=pad)\n",
    "#         print \"Conv41: self.net['conv_4_1']\", self.net['conv_4_1'].output_shape\n",
    "#         self.net['dropout4'] = DropoutLayer(self.net['conv_4_1'], p=0.2)\n",
    "#         print \"Dropout4: self.net['dropout4']\", self.net['dropout4'].output_shape\n",
    "#         self.net['conv_4_2'] = Conv2DLayer(batch_norm(self.net['dropout4']),\n",
    "#                                             num_filters=n_filters * 8,\n",
    "#                                             filter_size=filter_size,\n",
    "#                                             nonlinearity=nonlinearity,\n",
    "#                                             pad=pad)\n",
    "#         print \"Conv42: self.net['conv_4_2']\", self.net['conv_4_2'].output_shape\n",
    "        \n",
    "        ##\n",
    "        self.net['deconv1'] = Upscale2DLayer(batch_norm(self.net['conv_3_2']), 2)\n",
    "        print \"\\nDeconv1: self.net['deconv1']\", self.net['deconv1'].output_shape\n",
    "        self.net['concat1'] = ConcatLayer([self.net['deconv1'], self.net['conv_2_2']],\n",
    "                                          cropping=(None, None, \"center\", \"center\"))\n",
    "        print \"Concat1: self.net['concat1']\",self.net['concat1'].output_shape\n",
    "        self.net['expand_1_1'] = Conv2DLayer(self.net['concat1'],\n",
    "                                             num_filters=n_filters * 4,\n",
    "                                             filter_size=filter_size,\n",
    "                                             nonlinearity=nonlinearity,\n",
    "                                             pad=pad)\n",
    "        print \"Expand11: self.net['expand_1_1']\", self.net['expand_1_1'].output_shape\n",
    "        self.net['expand_1_2'] = Conv2DLayer(batch_norm(self.net['expand_1_1']),\n",
    "                                             num_filters=n_filters * 4,\n",
    "                                             filter_size=filter_size,\n",
    "                                             nonlinearity=nonlinearity,\n",
    "                                             pad=pad)\n",
    "        print \"Expand12: self.net['expand_1_2']\", self.net['expand_1_2'].output_shape\n",
    "        #\n",
    "        self.net['deconv2'] = Upscale2DLayer(batch_norm(self.net['expand_1_2']), 2)\n",
    "        print \"\\nDeconv2: self.net['deconv2']\", self.net['deconv2'].output_shape\n",
    "        self.net['concat2'] = ConcatLayer([self.net['deconv2'], self.net['conv_2_2']],\n",
    "                                          cropping=(None, None, \"center\", \"center\"))\n",
    "        print \"Concat2: self.net['concat2']\",self.net['concat2'].output_shape\n",
    "        self.net['expand_2_1'] = Conv2DLayer(self.net['concat2'],\n",
    "                                             num_filters=n_filters * 2,\n",
    "                                             filter_size=filter_size,\n",
    "                                             nonlinearity=nonlinearity,\n",
    "                                             pad=pad)\n",
    "        print \"Expand21: self.net['expand_2_1']\", self.net['expand_2_1'].output_shape\n",
    "        self.net['expand_2_2'] = Conv2DLayer(batch_norm(self.net['expand_2_1']),\n",
    "                                             num_filters=n_filters * 2,\n",
    "                                             filter_size=filter_size,\n",
    "                                             nonlinearity=nonlinearity,\n",
    "                                             pad=pad)\n",
    "        print \"Expand22: self.net['expand_2_2']\", self.net['expand_2_2'].output_shape\n",
    "        #\n",
    "        self.net['deconv3'] = Upscale2DLayer(batch_norm(self.net['expand_2_2']), 2)\n",
    "        print \"\\nDeconv3: self.net['deconv3'] \", self.net['deconv3'] .output_shape\n",
    "        self.net['concat3'] = ConcatLayer([self.net['deconv3'], self.net['conv_1_2']],\n",
    "                                          cropping=(None, None, \"center\", \"center\"))\n",
    "        print \"Concat3: self.net['concat3']\",self.net['concat3'].output_shape\n",
    "        self.net['expand_3_1'] = Conv2DLayer(self.net['concat3'],\n",
    "                                             num_filters=n_filters,\n",
    "                                             filter_size=filter_size,\n",
    "                                             nonlinearity=nonlinearity,\n",
    "                                             pad=pad)\n",
    "        print \"\\nExpand31: self.net['expand_3_1']\", self.net['expand_3_1'].output_shape\n",
    "        self.net['expand_3_2'] = Conv2DLayer(batch_norm(self.net['expand_3_1']),\n",
    "                                             n_filters,\n",
    "                                             filter_size,\n",
    "                                             nonlinearity=nonlinearity,\n",
    "                                             pad=pad)\n",
    "        print \"Expand32: self.net['expand_3_2']\", self.net['expand_3_2'].output_shape\n",
    "        #\n",
    "        self.net['output_segmentation'] = Conv2DLayer(self.net['expand_3_2'], \n",
    "                                                      nmb_out_classes, \n",
    "                                                      1, \n",
    "                                                      nonlinearity=lasagne.nonlinearities.sigmoid)\n",
    "        print \"self.net['output_segmentation']\", self.net['output_segmentation'].output_shape\n",
    "\n",
    "        self.net['dimshuffle'] = DimshuffleLayer(batch_norm(self.net['output_segmentation']), (1, 0, 2, filter_size))\n",
    "        print \"self.net['dimshuffle']\", self.net['dimshuffle'].output_shape\n",
    "\n",
    "        self.net['reshapeSeg'] = ReshapeLayer(self.net['dimshuffle'], (nmb_out_classes, -1))\n",
    "        print \"self.net['reshapeSeg']\", self.net['reshapeSeg'].output_shape\n",
    "\n",
    "        self.net['dimshuffle2'] = DimshuffleLayer(self.net['reshapeSeg'], (1, 0))\n",
    "        print \"self.net['dimshuffle2']\", self.net['dimshuffle2'].output_shape\n",
    "\n",
    "        self.net['output_flattened'] = NonlinearityLayer(self.net['reshapeSeg'],\n",
    "                                                         nonlinearity=lasagne.nonlinearities.softmax)\n",
    "        print \"self.net['output_flattened']\", self.net['output_flattened'].output_shape\n",
    "\n",
    "    def predict(self, X, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Input:  X\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'predict_fun'):\n",
    "            raise ValueError(\"you should add a valid predict_fun to this class\"\n",
    "                             \"(no automatic predict generates since X_layer isn't an InputLayer\")\n",
    "        return self.predict_fun(X)\n",
    "\n",
    "    def get_loss_components(self, target, weights):\n",
    "\n",
    "        target = T.transpose(target)\n",
    "        ce = lasagne.objectives.binary_crossentropy(self.pred_y, target)\n",
    "        ce_weighed = lasagne.objectives.aggregate(ce, weights=weights, mode='mean')\n",
    "\n",
    "        reg_l2 = regularize_network_params(self.outlayer_for_loss, l2) * 10 ** -5\n",
    "        acc = T.mean(T.eq(T.argmax(self.pred_y, axis=0), target), dtype=theano.config.floatX)\n",
    "\n",
    "        return ce_weighed, reg_l2, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\textbf{ Characteristics of NN}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: self.net['input'] [20, 3, 256, 256]\n",
      "\n",
      "Conv11: self.net['conv_1_1'] (20, 32, 254, 254)\n",
      "Dropout1: self.net['dropout1'] (20, 32, 254, 254)\n",
      "Conv12: self.net['conv_1_2'] (20, 32, 252, 252)\n",
      "\n",
      "Pool1: self.net['pool1'] (20, 32, 126, 126)\n",
      "Conv21: self.net['conv_2_1'] (20, 64, 124, 124)\n",
      "Dropout2: self.net['dropout2'] (20, 64, 124, 124)\n",
      "Conv22: self.net['conv_2_2'] (20, 64, 122, 122)\n",
      "\n",
      "Pool2: self.net['pool2'] (20, 64, 61, 61)\n",
      "Conv31: self.net['conv_3_1'] (20, 128, 59, 59)\n",
      "Dropout3: self.net['dropout3'] (20, 128, 59, 59)\n",
      "Conv32: self.net['conv_3_2'] (20, 128, 57, 57)\n",
      "\n",
      "Deconv1: self.net['deconv1'] (20, 128, 114, 114)\n",
      "Concat1: self.net['concat1'] (20, 192, 114, 114)\n",
      "Expand11: self.net['expand_1_1'] (20, 128, 112, 112)\n",
      "Expand12: self.net['expand_1_2'] (20, 128, 110, 110)\n",
      "\n",
      "Deconv2: self.net['deconv2'] (20, 128, 220, 220)\n",
      "Concat2: self.net['concat2'] (20, 192, 122, 122)\n",
      "Expand21: self.net['expand_2_1'] (20, 64, 120, 120)\n",
      "Expand22: self.net['expand_2_2'] (20, 64, 118, 118)\n",
      "\n",
      "Deconv3: self.net['deconv3']  (20, 64, 236, 236)\n",
      "Concat3: self.net['concat3'] (20, 96, 236, 236)\n",
      "\n",
      "Expand31: self.net['expand_3_1'] (20, 32, 234, 234)\n",
      "Expand32: self.net['expand_3_2'] (20, 32, 232, 232)\n",
      "self.net['output_segmentation'] (20, 2, 232, 232)\n",
      "self.net['dimshuffle'] (2, 20, 232, 232)\n",
      "self.net['reshapeSeg'] (2, 1076480)\n",
      "self.net['dimshuffle2'] (1076480, 2)\n",
      "self.net['output_flattened'] (2, 1076480)\n",
      "(20, 2, 232, 232) (2, 1076480)\n"
     ]
    }
   ],
   "source": [
    "#### LOAD NN ####\n",
    "cnn = uNet(X_layer,n_filters=N_FILTERS,nmb_out_classes=2,pad='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total weights: 841764\n"
     ]
    }
   ],
   "source": [
    "### WEIGHTS sanity check ###\n",
    "total_weights = int(T.sum([T.prod(w.shape) for w in cnn.weights]).eval())\n",
    "print \"Total weights:\", total_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\textbf{Objective loss, updates, train and eval fuctions}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### GROUND TRUTH and CLASS_WEIGHTS theano vectors ####\n",
    "Y_gt = T.ivector('Target Y integer')\n",
    "weights = T.vector('Loss weights')\n",
    "ce,reg_l2, acc = cnn.get_loss_components(Y_gt, weights)\n",
    "loss = ce+reg_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232, 232)\n"
     ]
    }
   ],
   "source": [
    "pred_img_shape = cnn.net['output_segmentation'].output_shape[2:]\n",
    "print pred_img_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax.0\n"
     ]
    }
   ],
   "source": [
    "prediction_train = cnn.pred_y\n",
    "print prediction_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "updates = lasagne.updates.adadelta(loss,cnn.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a convenience function to get the segmentation\n",
    "seg_output = lasagne.layers.get_output(cnn.outlayer_seg,X_inp)\n",
    "seg_output = seg_output.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_test = lasagne.layers.get_output(cnn.outlayer_for_loss, X_inp, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_func = theano.function([X_inp,Y_gt,weights], [ce,reg_l2,acc], updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### FOR DEBUG ####\n",
    "# from theano.compile.debugmode import DebugMode\n",
    "# theano.config.exception_verbosity='high'\n",
    "# T.cmp_sloppy=1\n",
    "# train_func = theano.function([X_inp,Y_gt], [loss, acc_train], updates=updates, mode=DebugMode(check_isfinite=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_func = theano.function([X_inp, Y_gt, weights], [ce,reg_l2,acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_segmentation = theano.function([X_inp], seg_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Note: Set weights for classes here ####\n",
    "lesion_weight = 1.\n",
    "nonlesion_weight = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_some_results(pred_fn, test_generator, BATCH_SIZE,path_to_save,  n_images=10, \n",
    "                    info = False, info_threshold=0.05):\n",
    "    \n",
    "    def plot(d,s,r):\n",
    "        fig = plt.figure(figsize=(12, 6))\n",
    "            \n",
    "        ax1 = fig.add_subplot(131)\n",
    "        ax1.imshow(d.transpose(1,2,0))\n",
    "        ax1.set_title('input')\n",
    "\n",
    "        ax2 = fig.add_subplot(132)\n",
    "        ax2.imshow(s[0])\n",
    "        ax2.set_title('gt')\n",
    "\n",
    "        ax3 = fig.add_subplot(133)\n",
    "        ax3.imshow(r)\n",
    "        ax3.set_title('prediction')\n",
    "\n",
    "        plt.savefig(path_to_save+\"{}.png\".format(fig_ctr))\n",
    "        plt.close()\n",
    "            \n",
    "    fig_ctr = 0\n",
    "    for data, seg in test_generator:\n",
    "        res = pred_fn(data)\n",
    "        for d, s, r in zip(data, seg, res):\n",
    "            print 'np.sum(s>0),np.sum(s==0), np.sum(r>0),np.sum(r==0)', \\\n",
    "            np.sum(s>0),np.sum(s==0), np.sum(r>0),np.sum(r==0)\n",
    "            if info:\n",
    "                info_percent = np.sum(s > 0)*1./ np.size(s.ravel())\n",
    "                if info_percent < info_threshold:\n",
    "                    pass\n",
    "                 \n",
    "                else: \n",
    "                    print 'info_percent', info_percent\n",
    "                    plot(d,s,r)\n",
    "                    fig_ctr += 1\n",
    "                    print 'done:', fig_ctr\n",
    "            else:\n",
    "                    plot(d,s,r)\n",
    "                    fig_ctr += 1\n",
    "                    print 'done:', fig_ctr\n",
    "        if fig_ctr > n_images:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\textbf{Train NN}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-10-25 09:52:43.648450\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "print dt.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.persistence import *\n",
    "import time, datetime, pytz\n",
    "from utils.persistence import *\n",
    "from visualizers.metrics import Metrics\n",
    "metrics = Metrics()\n",
    "from datetime import datetime as dt\n",
    "\n",
    "def train_nn (N_EPOCHS):\n",
    "    \n",
    "    with open(logs_path, \"a+\") as logs:\n",
    "                cur_time = dt.now(pytz.timezone('US/Eastern')).time()\n",
    "                logs.write(\"\\n\\nEval {}, \\nCurrent time {} \\n\"\\\n",
    "               .format(eval_name, cur_time.strftime(\"%Y-%m-%d %H:%M\")))\n",
    "                \n",
    "    losses = []    \n",
    "    epoch = 1\n",
    "\n",
    "    t_start = time.time()\n",
    "    \n",
    "    for i in range(N_EPOCHS):\n",
    "        print \"epoch\", epoch\n",
    "        n_batches = 0\n",
    "        t0 = time.time()\n",
    "        for j in range(N_BATCHES_PER_EPOCH):\n",
    "            data, target = train_generator.next()\n",
    "            target_flat = target.flatten()\n",
    "            if (i==0 and j==0): print '0 {}, 1 {}'.format(np.sum(target==0), np.sum(target==1))\n",
    "            # make a binary vector of weights for target elements\n",
    "            weights_target = np.where(target_flat<0.5, nonlesion_weight, lesion_weight).astype(np.float32)\n",
    "            ce_i, reg_i, acc_i = train_func(data.astype(np.float32),target_flat,weights_target)   \n",
    "            print 'ce_i, reg_i, acc_i', np.round(ce_i,3), np.round(reg_i,3), np.round(acc_i,3)\n",
    "            loss_i = ce_i\n",
    "            \n",
    "            metrics[\"train loss\"][epoch] = ce_i\n",
    "            metrics[\"train full objective\"][epoch] = loss_i\n",
    "            metrics[\"train reg\"][epoch] = reg_i\n",
    "            losses.append(loss_i)   \n",
    "            n_batches += 1\n",
    "            if n_batches > N_BATCHES_PER_EPOCH:\n",
    "                break\n",
    "\n",
    "        if epoch%10==0:\n",
    "            data, target = validation_generator.next()\n",
    "            target_flat = target.flatten()\n",
    "            weights_target = np.where(target_flat<0.5, nonlesion_weight, lesion_weight).astype(np.float32)\n",
    "            ce_i, reg_i, acc_i = eval_func(data.astype(np.float32), target_flat, weights_target)\n",
    "#             print 'eval: ce_i, reg_i, acc_i', ce_i, reg_i, acc_i\n",
    "            loss_i = ce_i\n",
    "            \n",
    "            metrics[\"test loss\"][epoch] = ce_i\n",
    "            metrics[\"test full objective\"][epoch] = loss_i\n",
    "            metrics[\"test reg\"][epoch] = reg_i \n",
    "\n",
    "\n",
    "        if epoch%10==0:\n",
    "            print \"epoch:\",epoch\n",
    "            print 'mean loss for the last 10 epochs:', np.round(np.mean(losses[-10:]),3)\n",
    "            with open(logs_path, \"a+\") as logs:\n",
    "                cur_time = dt.now(pytz.timezone('US/Eastern'))\n",
    "                logs.write(\"\"\"\\nEpoch {}, \\nCurrent time {} \\nmean loss for the last 10 epochs:{}\"\"\"\\\n",
    "               .format(epoch,cur_time.strftime(\"%Y-%m-%d %H:%M\"), np.round(np.mean(losses[-10:]),3)))\n",
    "\n",
    "        if epoch%100==0:\n",
    "            # plot and save metrics\n",
    "            fig = plt.figure(figsize=[15,5])\n",
    "            path_save_plot = \"MetricsEpoch{}.png\".format(epoch)\n",
    "            metrics.plot(save=True, path_to_save=path_save_plot)\n",
    "            # weights snapshort\n",
    "            plt.close()\n",
    "            file_weights_path = eval_name + '_weights{}epoch'.format(epoch) + '.pickle'\n",
    "            save(cnn.outlayer_for_loss, file_weights_path)\n",
    "            \n",
    "            plot_some_results(validation_generator, test_gen, BATCH_SIZE, \n",
    "                              info=True, n_images=4,path_to_save='.')\n",
    "\n",
    "        epoch+=1\n",
    "        print 'time for epoch: {} mins'\\\n",
    "        .format(round((time.time() - t0)/60.0, 3))\n",
    "    print 'Overall time: {} mins'.format(round((time.time() - t_start)/60.0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_generator = random_crop_generator(batch_generator(X_train, Y_train, BATCH_SIZE), \n",
    "                                        info=True, crop_size=PATCH_SIZE, target_crop_size=pred_img_shape)\n",
    "train_generator = threaded_generator(train_generator, num_cached=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtain images of the same size for validation\n",
    "validation_generator = random_crop_generator(batch_generator(X_valid, Y_valid, BATCH_SIZE), \n",
    "                                             info=True, crop_size=PATCH_SIZE, target_crop_size=pred_img_shape)\n",
    "validation_generator = threaded_generator(validation_generator, num_cached=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_EPOCHS =  3000\n",
      "epoch 1\n",
      "0 1021581, 1 54899\n",
      "ce_i, reg_i, acc_i 0.699 0.018 0.414\n",
      "ce_i, reg_i, acc_i 0.95 0.018 0.498\n",
      "ce_i, reg_i, acc_i 0.735 0.018 0.501\n",
      "ce_i, reg_i, acc_i 0.743 0.018 0.498\n",
      "ce_i, reg_i, acc_i 0.772 0.018 0.497\n",
      "ce_i, reg_i, acc_i 0.779 0.018 0.499\n",
      "ce_i, reg_i, acc_i 0.879 0.018 0.487\n",
      "ce_i, reg_i, acc_i 0.692 0.018 0.493\n",
      "ce_i, reg_i, acc_i 0.779 0.018 0.501\n",
      "ce_i, reg_i, acc_i 0.775 0.018 0.481\n",
      "time for epoch: 1.81 mins\n",
      "epoch 2\n"
     ]
    }
   ],
   "source": [
    "#### TRAIN NN ####\n",
    "logs_path = './logs.txt'\n",
    "from utils.persistence import *\n",
    "import time\n",
    "\n",
    "print \"N_EPOCHS = \", N_EPOCHS\n",
    "nn_weights = results_eval_path + eval_name + \"_weights.pickle\"\n",
    "TRAIN_NN=True\n",
    "if TRAIN_NN:\n",
    "    train_nn(N_EPOCHS) \n",
    "else:\n",
    "    try:\n",
    "        a = load(cnn.outlayer_for_loss, nn_weights)\n",
    "    except:\n",
    "        print \"problem with weights loading, nn is being trained\"\n",
    "        train_nn(N_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\textbf{Save weights}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.persistence import *\n",
    "\n",
    "if not os.path.exists(results_eval_path):\n",
    "    os.makedirs(results_eval_path)\n",
    "    \n",
    "file_path = results_eval_path + eval_name + '_weights' + '.pickle'\n",
    "save(cnn.outlayer_for_loss, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### TEST SAVING ####\n",
    "try:\n",
    "    a = load(cnn.outlayer_for_loss, nn_weights)\n",
    "except:\n",
    "    print \"The problem occured. Weights were not saved\"\n",
    "else: print 'Weights were successfully saved to the file: ', file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* $ \\textbf{Visualizations}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create some png files showing (raw image, ground truth, prediction)\n",
    "test_gen = random_crop_generator(batch_generator(X_test, Y_test, BATCH_SIZE), PATCH_SIZE)\n",
    "path_to_save = os.path.join(results_eval_path + eval_name)\n",
    "print 'plots are saved to:', path_to_save\n",
    "plot_some_results(get_segmentation, test_gen, BATCH_SIZE, info=True, path_to_save=path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "files = [os.path.join(results_eval_path,f) for f in os.listdir(results_eval_path) if f.endswith('.png')][:30]\n",
    "print files\n",
    "\n",
    "for f in files:\n",
    "    plt.figure()\n",
    "    plt.imshow(plt.imread(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f268dfdcb10>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAFkCAYAAAB1rtL+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSJKkZgYJSZLUzCAhSZKa/T9Cge0jrwnhVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2696a0cc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = 'MetricsEpoch2.png'\n",
    "plt.imshow(plt.imread(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='c'/>\n",
    "# Conclusions\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
