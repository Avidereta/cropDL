{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment template. \n",
    "## Note: \n",
    "This is a template for expariment, which can be run in /run_*ipynb file\n",
    "\n",
    "In this experiment we use Unet NN structure, general idea is described https://arxiv.org/pdf/1505.04597.pdf .\n",
    "Model for the current experiment can be found in code/model/models/UnetDeepSoftmax. \n",
    "\n",
    "The prediction is a 3D Tensor after softmax, contained 2 masks for lesions and nonlesion probability distributions.  \n",
    "\n",
    "A weighted loss is used to tackle unbalance in number of lesion/nonlesion. Take a look at parameters lesion_weights, nonlesion_weights (1, 0.1 for this experiment)\n",
    "\n",
    "For ground truth is presented as ellipses built on line segments annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# description = {here could be a short description of the experiment}\n",
    "\n",
    "# specific name of the experiment\n",
    "eval_name = 'unet_weightedLoss_gtEllip'\n",
    "\n",
    "if eval_name is None:\n",
    "    with open(path_to_dir+'eval_name.txt') as data_file:    \n",
    "        eval_name = json.load(data_file)\n",
    "print \"eval_name is\", eval_name "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: segmentation of the image\n",
    "***\n",
    "### Content:\n",
    "* [Settings and experiment parameters](#sep)\n",
    "* [Load Data](#ld)\n",
    "* [Training and visualizing results](#lav)\n",
    "* [Conclusions](#c)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Togle ON/OFF the raw code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "CODE WAS HIDDEN. TO TOGGLE ON/OFF THE RAW CODE, CLICK\n",
    "<a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"sep\"/>\n",
    "# Settings and experiment parameters\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%env THEANO_FLAGS=\"device=gpu1\"\n",
    "\n",
    "### Check theano ####\n",
    "import theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables and paths \n",
    "* $\\textbf{Add the main directory '.../code' to   sys.path}$. \n",
    "\n",
    "The following directory was added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Add the main dir to sys ####\n",
    "\n",
    "import os, sys\n",
    "\n",
    "parentdir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
    "print parentdir\n",
    "\n",
    "sys.path.insert(0, parentdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\textbf{Put your certain values or None}$ (then use run.ipynb to set them outside).\n",
    "\n",
    "Note: In case you put None, files with parameters should be in the same directory with this .ipynb file \n",
    "(else change path_to_dir by what ever you want)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_NN = True\n",
    "\n",
    "N_FILTERS = 32\n",
    "BATCH_SIZE = 50\n",
    "N_EPOCHS = 10000\n",
    "PATCH_SIZE = 290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read global params from files\n",
    "import json\n",
    "\n",
    "print \"N_FILTERS = \", N_FILTERS\n",
    "print \"BATCH_SIZE = \", BATCH_SIZE\n",
    "print \"N_EPOCHS = \", N_EPOCHS\n",
    "print \"PATCH SIZE = \", PATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# txt files with paths to segmentation image and input image\n",
    "from config import txt_train, txt_valid, txt_test\n",
    "\n",
    "from config import results_path\n",
    "# path to save the results for THIS experiment\n",
    "results_eval_path = results_path + eval_name + \"/\"\n",
    "\n",
    "print 'txt train path:', txt_train\n",
    "print 'txt valid path:', txt_valid\n",
    "print 'txt test path:', txt_test\n",
    "\n",
    "print 'results_path', results_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### IMPORTS ####\n",
    "import matplotlib\n",
    "matplotlib.use('Pdf')\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='ld'/>\n",
    "# Load Data\n",
    "</a>\n",
    "\n",
    "* Load and visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_data(txt, augment=True, masked_data=False):\n",
    "    ':@return: lists of paths'\n",
    "    data_imgs = []\n",
    "    target_imgs = []\n",
    "    if masked_data:\n",
    "        masked_data_imgs = []\n",
    "    else: masked_data_imgs = None\n",
    "        \n",
    "    with open(txt, 'r') as fin:\n",
    "        lines = fin.read().splitlines()\n",
    "    for line in lines:\n",
    "        data_imgs.append(line.split(' ')[1]) \n",
    "        target_imgs.append(line.split(' ')[0])\n",
    "        if masked_data:\n",
    "            masked_data_imgs.append(line.split(' ')[2])\n",
    "    \n",
    "    assert(len(data_imgs) == len(target_imgs))\n",
    "    data_imgs.sort()\n",
    "    target_imgs.sort()\n",
    "    if masked_data:\n",
    "        assert(len(data_imgs) == len(masked_data_imgs))\n",
    "        masked_data_imgs.sort()\n",
    "    \n",
    "    return data_imgs, target_imgs, masked_data_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, Y_train, X_mask_train = load_data(txt_train, masked_data=True)\n",
    "X_valid, Y_valid, X_mask_valid = load_data(txt_valid, masked_data=True)\n",
    "X_test, Y_test, X_mask_test = load_data(txt_test, masked_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Train set: data, target, masks', len(X_train), len(Y_train), len(X_mask_train)\n",
    "print 'Valid set: data, target, masks', len(X_valid), len(Y_valid), len(X_mask_valid)\n",
    "print 'Test set: data, target, masks', len(X_test), len(Y_test), len(X_mask_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='lav'/>\n",
    "# Training and Visualizing\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.generator import random_crop_generator, threaded_generator\n",
    "from utils.generator import batch_generator_from_paths as batch_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\textbf{ Characteristics of input images and the input layer}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### PREPARE DATA FOR NN ####\n",
    "\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lasagne.layers import InputLayer\n",
    "\n",
    "X_data = plt.imread(X_train[0])\n",
    "print 'Image shape:', X_data.shape\n",
    "\n",
    "nmb_channels, inp_shape = X_data.shape[2], X_data.shape[:2]\n",
    "print 'Image size:', inp_shape\n",
    "print \"Number of channels:\", nmb_channels\n",
    "\n",
    "X_inp = T.tensor4('X_inp')\n",
    "X_layer = InputLayer([BATCH_SIZE, nmb_channels, PATCH_SIZE, \\\n",
    "                      PATCH_SIZE], input_var=X_inp,name='input')\n",
    "\n",
    "print \"Input layer shape:\", X_layer.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from models.unetDeepSoftmax import uNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\textbf{ Characteristics of NN}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### LOAD NN ####\n",
    "cnn = uNet(X_layer,n_filters=N_FILTERS,nmb_out_classes=2,\\\n",
    "           pad='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### WEIGHTS sanity check ###\n",
    "total_weights = int(T.sum([T.prod(w.shape) for w in cnn.weights]).eval())\n",
    "print \"Total weights:\", total_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\textbf{Objective loss, updates, train and eval fuctions}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### GROUND TRUTH and CLASS_WEIGHTS theano vectors ####\n",
    "Y_gt = T.ivector('Target Y integer')\n",
    "weights = T.vector('Loss weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### LOSS ####\n",
    "ce,reg_l2, acc, max_0_pred, max_1_pred = cnn.get_loss_components(Y_gt, weights)\n",
    "loss = ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "updates = lasagne.updates.adam(loss,cnn.weights,learning_rate=1e-4,\\\n",
    "                               beta1=0.8,beta2=0.999,epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_func = theano.function([X_inp,Y_gt,weights], [ce,reg_l2, acc, max_0_pred, max_1_pred], \\\n",
    "                             updates=updates, on_unused_input='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### FOR DEBUG ####\n",
    "# from theano.compile.debugmode import DebugMode\n",
    "# theano.config.exception_verbosity='high'\n",
    "# T.cmp_sloppy=1\n",
    "# train_func = theano.function([X_inp,Y_gt], [loss, acc_train], updates=updates, mode=DebugMode(check_isfinite=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_func = theano.function([X_inp, Y_gt, weights], [ce,reg_l2,acc,max_0_pred, max_1_pred], on_unused_input='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print cnn.outlayer_seg.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# seg_output = lasagne.layers.get_output(cnn.outlayer_seg, X_inp)\n",
    "# seg_output = seg_output.argmax(axis=1)\n",
    "# get_segmentation = theano.function([X_inp], seg_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import scipy.misc\n",
    "\n",
    "# layers = ['pool4','convde_4_2']\n",
    "\n",
    "# layer_output = {}\n",
    "# get_fmap = {}\n",
    "\n",
    "# for layer_name in layers:\n",
    "#     layer_output[layer_name] = lasagne.layers.get_output(cnn.net[layer_name], X_inp)\n",
    "#     get_fmap[layer_name] = theano.function([X_inp], layer_output[layer_name])\n",
    "\n",
    "# def save_feature_maps(layer_name, data, target, path_to_save, epoch=0):\n",
    "#     fmaps_batch = get_fmap[layer_name](data)\n",
    "#     fmaps = fmaps_batch[0] \n",
    "#     scipy.misc.imsave(os.path.join(path_to_save, 'data_epoch%d.jpg'\\\n",
    "#                                    %epoch),data[0].transpose(1,2,0))\n",
    "#     scipy.misc.imsave(os.path.join(path_to_save, 'target_epoch%d.jpg'\\\n",
    "#                                    %epoch),target[0,0,:,:])\n",
    "#     for i,fmap in enumerate(fmaps):\n",
    "#         scipy.misc.imsave(os.path.join(path_to_save, 'fmap_epoch%d_'\\\n",
    "#                                 %epoch+layer_name+'_%d.jpg'%i), fmap)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Note: Set weights for classes here ####\n",
    "lesion_weight = 1.\n",
    "nonlesion_weight = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.predict_full_img import predict_full_img, process_img_for_plot, plot_dsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from visualizers.plot_predictions import plot_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_predictions(pred_fn, generator, BATCH_SIZE, path_to_save, \\\n",
    "                     n_images=10,info = False, info_threshold=0.005):\n",
    "    cnt_images = 0            \n",
    "    for data, seg, masked_data in generator:\n",
    "        # shape [batch_size, nmb_classes=2, output_shape. output_shape]\n",
    "        pred = pred_fn(data)\n",
    "        \n",
    "        # if None transform to list for iteration\n",
    "        if masked_data is None:\n",
    "            masked_data=[None]*len(data)\n",
    "            \n",
    "        for i, (d, s, md, p) in enumerate(zip(data, seg, masked_data, pred)):\n",
    "            # use only images with informational content (nmb lesion pixels) more than threshold\n",
    "            if info:\n",
    "                info_percent = np.sum(s > 0)*1./ np.size(s.ravel())\n",
    "                if info_percent < info_threshold:\n",
    "                    pass                 \n",
    "                else: \n",
    "                    if md is not None:\n",
    "                        img_edged, gt_edged, plot_img_gt, plot_img_pred, diff_gt_pred = \\\n",
    "                        process_img_for_plot(d.transpose(1,2,0), s[0], p[0], 0.3, md.transpose(1,2,0))\n",
    "                    else:\n",
    "                        img_edged, gt_edged, plot_img_gt, plot_img_pred, diff_gt_pred = \\\n",
    "                        process_img_for_plot(d.transpose(1,2,0), s[0], p[0], rate=0.3)\n",
    "                        \n",
    "                    plot_dsp(p[0], img_edged, gt_edged, plot_img_gt, plot_img_pred, diff_gt_pred, \\\n",
    "                         path_to_save=path_to_save+\"{}.png\".format(i))\n",
    "                    \n",
    "                    cnt_images+=1\n",
    "                    \n",
    "            # no informational content\n",
    "            else:\n",
    "                if md is not None:\n",
    "                    img_edged, gt_edged, plot_img_gt, plot_img_pred, diff_gt_pred = \\\n",
    "                    process_img_for_plot(d.transpose(1,2,0), s[0], p[0], 0.3, md.transpose(1,2,0))\n",
    "                else:\n",
    "                    img_edged, gt_edged, plot_img_gt, plot_img_pred, diff_gt_pred = \\\n",
    "                    process_img_for_plot(d.transpose(1,2,0), s[0], p[0], rate=0.3)\n",
    "                \n",
    "                plot_dsp(p[0], img_edged, gt_edged, plot_img_gt, plot_img_pred, diff_gt_pred, \\\n",
    "                     path_to_save=path_to_save+\"{}.png\".format(i))\n",
    "                \n",
    "                cnt_images+=1\n",
    "        if cnt_images > n_images:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\textbf{Predict full image}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\textbf{Folders with results}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "\n",
    "path_metrics_plot = './metrics_plot'\n",
    "path_pred_small_img = './pred_small_img'\n",
    "path_pred_full_img = './pred_full_img'\n",
    "path_snapshots = './snapshots'\n",
    "path_fmaps = './fmaps'\n",
    "\n",
    "for folder in [path_metrics_plot, path_pred_small_img, path_pred_full_img, path_snapshots,\\\n",
    "              path_fmaps]:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\textbf{Data Generators}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RS_TRAIN = 10 # random seed\n",
    "\n",
    "batch_gen = batch_generator(X_train, Y_train, BATCH_SIZE, \\\n",
    "                            random_seed=RS_TRAIN, masked_data_paths=X_mask_train)\n",
    "\n",
    "train_generator = random_crop_generator(batch_gen, \n",
    "                                        info=True, \n",
    "                                        crop_size=cnn.input_img_shape, \n",
    "                                        target_crop_size=cnn.pred_img_shape, \n",
    "                                        random_seed=RS_TRAIN)\n",
    "\n",
    "train_generator = threaded_generator(train_generator, num_cached=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RS_VALID = 20 # random seed\n",
    "\n",
    "batch_gen = batch_generator(X_valid, Y_valid, BATCH_SIZE, \\\n",
    "                            random_seed=RS_VALID, masked_data_paths= X_mask_valid)\n",
    "\n",
    "validation_generator = random_crop_generator(batch_gen, \n",
    "                                             info=True, \n",
    "                                             crop_size=cnn.input_img_shape, \n",
    "                                             target_crop_size=cnn.pred_img_shape,\n",
    "                                             random_seed=RS_VALID)\n",
    "\n",
    "validation_generator = threaded_generator(validation_generator, num_cached=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_fullimg_gen = batch_generator(X_valid, Y_valid, BATCH_SIZE, \\\n",
    "                                random_seed=RS_VALID, info=True, info_threshold = 0.01,\\\n",
    "                                   masked_data_paths = X_mask_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from visualizers.metrics_visualizer import MetricsVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\textbf{Train NN}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NMB_SAMPLES = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.persistence import *\n",
    "import time, datetime, pytz\n",
    "from visualizers.metrics import Metrics\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, recall_score, precision_score\n",
    "\n",
    "\n",
    "metrics = Metrics()\n",
    "acc_metrics = Metrics()\n",
    "\n",
    "def cur_time_fn():\n",
    "    return dt.now(pytz.timezone('US/Eastern')).strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "def train_nn (N_EPOCHS):\n",
    "    \n",
    "    with open(logs_path, \"a+\") as logs:\n",
    "                cur_time = cur_time_fn()\n",
    "                logs.write(\"\\n\\nEval {}, \\nCurrent time {} \\n\"\\\n",
    "               .format(eval_name, cur_time))\n",
    "                \n",
    "    losses = [] \n",
    "    losses_val = []\n",
    "    accs = []\n",
    "    accs_val = []\n",
    "    epoch = 1\n",
    "\n",
    "    t_start = time.time()\n",
    "    \n",
    "    for i in range(N_EPOCHS):\n",
    "        \n",
    "        print \"\\nepoch\", epoch\n",
    "        n_batches = 0\n",
    "        t0 = time.time()\n",
    "        \n",
    "        ## generate train batch\n",
    "        data, target, _ = train_generator.next()\n",
    "        target_flat = target.flatten()\n",
    "        ## weights for target elements\n",
    "        weights_target = np.where(target_flat<0.5, nonlesion_weight, lesion_weight).astype(np.float32)\n",
    "        ## compute loss for train batch \n",
    "        ce_i, reg_i, acc_i, max_pred_i, min_pred_i = \\\n",
    "                train_func(data.astype(np.float32),target_flat,weights_target)   \n",
    "        \n",
    "        print \"sum, max_pred, min_pred\", max_pred_i[0]+min_pred_i[1], max_pred_i, min_pred_i\n",
    "        ## sanity check of metrics\n",
    "        print 'Loss sanity check: ce_i %.3f, reg_i %.3f, acc_i %.3f'%(ce_i,reg_i,acc_i)    \n",
    "            \n",
    "        ## approximate class balance info\n",
    "        if epoch==1:\n",
    "            nmb_nonles, nmb_les = np.sum(target==0), np.sum(target==1)\n",
    "            class_balance_info = \"\\nClass Balance for 1 epoch: rate {:.2f}, nonlesions {}, lesions {}\\n\"\\\n",
    "                                    .format(nmb_les*1./nmb_nonles, nmb_nonles, nmb_les)            \n",
    "            print class_balance_info\n",
    "            with open(logs_path, \"a+\") as logs:\n",
    "                logs.write(class_balance_info)\n",
    "\n",
    "        loss_i = ce_i\n",
    "        metrics[\"train loss\"][epoch] = loss_i\n",
    "#         metrics[\"train reg\"][epoch] = reg_i\n",
    "        acc_metrics[\"train acc\"][epoch] = acc_i\n",
    "        losses.append(loss_i) \n",
    "        accs.append(acc_i)\n",
    "            \n",
    "        ## save metrics for train and validation\n",
    "        if epoch%10==0:\n",
    "            \n",
    "            ## validation batch\n",
    "            data, target, masked_data = validation_generator.next()\n",
    "            target_flat = target.flatten()\n",
    "            weights_target = np.where(target_flat<0.5, nonlesion_weight, lesion_weight).astype(np.float32)\n",
    "            ce_i, reg_i, acc_i, max_pred_i, min_pred_i = \\\n",
    "                    eval_func(data.astype(np.float32), target_flat, weights_target)\n",
    "            loss_i = ce_i\n",
    "            \n",
    "            metrics[\"test loss\"][epoch] = loss_i\n",
    "#             metrics[\"test reg\"][epoch] = reg_i \n",
    "            acc_metrics[\"test acc\"][epoch] = acc_i\n",
    "            losses_val.append(loss_i)\n",
    "            accs_val.append(acc_i)\n",
    "\n",
    "            print('#'*30)\n",
    "            mean_train_loss = np.mean(losses[-10:])\n",
    "            print('%d \\t| ce\\t| %.3f\\t| %.3f'%(epoch, mean_train_loss, losses_val[-1]))\n",
    "#             print('%d \\t| auc| %.3f\\t| %.3f'%(epoch, np.mean(metrics[\"train auc\"][-10:]), auc_i))\n",
    "            print('#'*30)\n",
    "            \n",
    "            with open(logs_path, \"a+\") as logs:\n",
    "                cur_time = cur_time_fn()\n",
    "                logs.write(\"\"\"\\nEpoch %d\\t| Train Loss %.3f\\t| Val Loss %.3f\\t| Train ACC %.3f\\t| Val ACC %.3f\\t |Cur time: %s\"\"\"\\\n",
    "               %(epoch, mean_train_loss, losses_val[-1], np.mean(accs[-10:]), acc_i, cur_time))\n",
    "        \n",
    "        if epoch%200==0:\n",
    "            ## plot and save metrics evaluation\n",
    "            fig = plt.figure(figsize=[15,5])\n",
    "            name = eval_name+\"_metrics{}epoch.png\".format(epoch)\n",
    "            path_save_plot = join(path_metrics_plot,name)\n",
    "            metrics.plot()\n",
    "            fig.savefig(path_save_plot)\n",
    "            fig = plt.figure(figsize=[15,5])\n",
    "            name = eval_name+\"_ACCmetrics{}epoch.png\".format(epoch)\n",
    "            path_save_plot = join(path_metrics_plot,name)\n",
    "            acc_metrics.plot()\n",
    "            fig.savefig(path_save_plot)\n",
    "\n",
    "            ## weights snapshort\n",
    "            name = eval_name + '_weights{}epoch'.format(epoch) + '.pickle'\n",
    "            file_weights_path = join(path_snapshots, name)\n",
    "            save(cnn.outlayer_for_loss, file_weights_path)\n",
    "            \n",
    "            ## visualize small predictions\n",
    "            name = eval_name+'_pred_small_img{}epoch'.format(epoch)\n",
    "            plot_predictions(cnn.predict,validation_generator,BATCH_SIZE,info=True, n_images=NMB_SAMPLES,\n",
    "                              path_to_save=join(path_pred_small_img, name))\n",
    "        \n",
    "        ## predict full validation image\n",
    "        if epoch%400==0:\n",
    "            with open(logs_path, \"a+\") as logs:\n",
    "                logs.write(\"\"\"\\nPredicting full image...\\t| Cur time: %s\"\"\"%(cur_time_fn()))\n",
    "                \n",
    "            data, target, masked_data = valid_fullimg_gen.next()\n",
    "            \n",
    "            print cur_time_fn(), 'Predicting full image...'\n",
    "            pred = predict_full_image(data, model=cnn) \n",
    "            print cur_time_fn(), 'Done. Process for plot...'\n",
    "            \n",
    "            with open(logs_path, \"a+\") as logs:\n",
    "                logs.write(\"\"\"\\nDone.\\t| Cur time: %s\\t| Plotting...\"\"\"%(cur_time_fn()))\n",
    "\n",
    "            # if None transform to list for iteration\n",
    "            if masked_data is None:\n",
    "                masked_data=[None]*len(data)\n",
    "            \n",
    "            for i, (d, s, md, p) in enumerate(zip(data, target, masked_data, pred)):\n",
    "                p_les = p[1]\n",
    "                p_nles = p[0]\n",
    "                if md is not None:\n",
    "                    img_edged, gt_edged, plot_img_gt, plot_img_pred, diff_gt_pred = \\\n",
    "                    process_img_for_plot(d.transpose(1,2,0), s[0], p_les, 0.3, md.transpose(1,2,0))\n",
    "                else:\n",
    "                    img_edged, gt_edged, plot_img_gt, plot_img_pred, diff_gt_pred = \\\n",
    "                    process_img_for_plot(d.transpose(1,2,0), s[0], p_les, rate=0.3)\n",
    "        \n",
    "                np.save(join(path_pred_full_img,'pred{}epoch{}'.format(epoch,i)), p_les)\n",
    "                np.save(join(path_pred_full_img,'pred_oppos{}epoch{}'.format(epoch,i)), p_nles)\n",
    "                np.save(join(path_pred_full_img,'img_edged{}epoch{}'.format(epoch,i)), img_edged)\n",
    "                np.save(join(path_pred_full_img,'gt_edged{}epoch{}'.format(epoch,i)), gt_edged)\n",
    "                \n",
    "                name = 'pred_full_img{}epoch{}.png'.format(epoch,i)\n",
    "                plot_dsp(p_les, img_edged, gt_edged, plot_img_gt, plot_img_pred, diff_gt_pred, \\\n",
    "                         pred_map2 = p_nles, bin_pred = p.argmax(axis=0), path_to_save=join(path_pred_full_img,name))\n",
    "                print i, 'saved and ploted'                \n",
    "                if i > NMB_SAMPLES: break\n",
    "            \n",
    "            with open(logs_path, \"a+\") as logs:\n",
    "                logs.write(\"\"\"\\nDone.\\t| Cur time: %s\"\"\"%(cur_time_fn()))\n",
    "            \n",
    "            np.save(join(path_snapshots,'losses.npy'), losses)\n",
    "            np.save(join(path_snapshots, 'losses_val.npy'), losses_val)\n",
    "            np.save(join(path_snapshots,'acc.npy'), accs)\n",
    "            np.save(join(path_snapshots, 'acc_val.npy'), accs_val)\n",
    "                    \n",
    "        \n",
    "#         # save feature maps\n",
    "#         if epoch%1000==0:  \n",
    "#             for l in layers:\n",
    "#                 try:\n",
    "#                     save_feature_maps(l, data, target, './fmaps', epoch)\n",
    "#                 except: pass\n",
    "\n",
    "\n",
    "        epoch+=1\n",
    "        print 'time for epoch: %.2f mins'%((time.time() - t0)/60.)\n",
    "    print 'Overall time: %.2f mins'%((time.time() - t_start)/60.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### TRAIN NN ####\n",
    "logs_path = './logs.txt'\n",
    "\n",
    "print \"N_EPOCHS = \", N_EPOCHS\n",
    "\n",
    "# nn_weights = './snapshots/debug_weights400epoch.pickle'\n",
    "# print 'path to nn weights', nn_weights\n",
    "\n",
    "try:\n",
    "#     print \"\\nLoading weights...\"\n",
    "    a = load(cnn.outlayer_for_loss, nn_weights)\n",
    "except:\n",
    "    print \"problem with weights loading, nn is being trained\\n\"\n",
    "else: \n",
    "    print \"weights are loaded\\n\"\n",
    "if TRAIN_NN:\n",
    "    train_nn(N_EPOCHS) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.persistence import *\n",
    "import time, datetime, pytz\n",
    "from visualizers.metrics import Metrics\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, recall_score, precision_score\n",
    "\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "def cur_time_fn():\n",
    "    return dt.now(pytz.timezone('US/Eastern')).strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "def apply_nn(N):\n",
    "    \n",
    "    with open(logs_path, \"a+\") as logs:\n",
    "                cur_time = cur_time_fn()\n",
    "                logs.write(\"\\n\\nVALIDATION. Eval {}, \\nCurrent time {} \\n\"\\\n",
    "               .format(eval_name, cur_time))\n",
    "    epoch = 1\n",
    "    losses_val = []\n",
    "    accs_val = []\n",
    "    t_start = time.time()\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        print \"\\nepoch\", epoch\n",
    "        n_batches = 0\n",
    "       \n",
    "        ## save metrics for validation\n",
    "        \n",
    "        ## validation batch\n",
    "        data, target = validation_generator.next()\n",
    "        target_flat = target.flatten()\n",
    "        weights_target = np.where(target_flat<0.5, nonlesion_weight, lesion_weight).astype(np.float32)\n",
    "        ce_i, reg_i, acc_i, max_pred_i, min_pred_i = \\\n",
    "                eval_func(data.astype(np.float32), target_flat, weights_target)\n",
    "        loss_i = ce_i\n",
    "\n",
    "        metrics[\"test loss\"][epoch] = loss_i\n",
    "#             metrics[\"test reg\"][epoch] = reg_i \n",
    "        acc_metrics[\"test acc\"][epoch] = acc_i\n",
    "        losses_val.append(loss_i)\n",
    "        accs_val.append(acc_i)\n",
    "\n",
    "        print('#'*30)\n",
    "        print('%d \\t| ce |  %.3f'%(epoch, losses_val[-1]))\n",
    "        print('#'*30)\n",
    "\n",
    "        with open(logs_path, \"a+\") as logs:\n",
    "            cur_time = cur_time_fn()\n",
    "            logs.write(\"\"\"\\nIteration %d\\t|| Val Loss %.3f\\t | Cur time: %s\"\"\"\\\n",
    "           %(epoch, losses_val[-1], cur_time))\n",
    "        \n",
    "        ### PLOTTING\n",
    "        ## visualize small predictions\n",
    "        print cur_time_fn(), 'Plot_predictions..'\n",
    "        plot_predictions(get_segmentation,validation_generator,BATCH_SIZE,info=True, n_images=NMB_SAMPLES,\n",
    "                          path_to_save='predictions/predictions_iteration{}.png'.format(epoch))\n",
    "        print cur_time_fn(), \"Done.\"\n",
    "        \n",
    "        ##FULL\n",
    "        ## predict full validation image\n",
    "        data, target = valid_fullimg_gen.next()\n",
    "\n",
    "        print cur_time_fn(), 'Predicting full image...'\n",
    "        pred = predict_full_image(data, model=cnn) \n",
    "        plt.imshow(pred[0,0])\n",
    "        plt.show()\n",
    "        print cur_time_fn(), 'Done. Process for plot...'\n",
    "\n",
    "        for i, (d,gt,p) in enumerate(zip(data, target, pred)):\n",
    "            img_edged, gt_edged, plot_img_gt, plot_img_pred, diff_gt_pred = \\\n",
    "                process_img_for_plot(d.transpose(1,2,0), gt[0], p[0], rate=0.3)\n",
    "            print i, 'process_img_for_plot'\n",
    "            plot_dsp(p[0], img_edged, gt_edged, plot_img_gt, plot_img_pred, diff_gt_pred, \\\n",
    "                     path_to_save='pred_full_img/pred_full_img_iteration{}_{}.png'.format(epoch,i), show=True)\n",
    "            if i > NMB_SAMPLES: break\n",
    "        \n",
    "#         # save feature maps\n",
    "#         if epoch%1000==0:  \n",
    "#             for l in layers:\n",
    "#                 try:\n",
    "#                     save_feature_maps(l, data, target, './fmaps', epoch)\n",
    "#                 except: pass\n",
    "\n",
    "\n",
    "        epoch+=1\n",
    "        print 'time for epoch: %.2f mins'%((time.time() - t0)/60.)\n",
    "    print 'Overall time: %.2f mins'%((time.time() - t_start)/60.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### TRAIN NN ####\n",
    "logs_path = './logs.txt'\n",
    "\n",
    "N = 10\n",
    "\n",
    "nn_weights = 'snapshots/'+ 'unet_adam_lr1e-2_weights8000epoch.pickle'\n",
    "# print 'path to nn weights', nn_weights\n",
    "\n",
    "try:\n",
    "#     print \"\\nLoading weights...\"\n",
    "    a = load(cnn.outlayer_for_loss, nn_weights)\n",
    "except:\n",
    "    print \"problem with weights loading, nn is being trained\\n\"\n",
    "else: \n",
    "    print \"weights are loaded\\n\"\n",
    "apply_nn(N) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\textbf{Save weights}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.persistence import *\n",
    "\n",
    "if not os.path.exists(results_eval_path):\n",
    "    os.makedirs(results_eval_path)\n",
    "    \n",
    "file_path = results_eval_path + eval_name + '_weights' + '.pickle'\n",
    "save(cnn.outlayer_for_loss, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### TEST SAVING ####\n",
    "try:\n",
    "    a = load(cnn.outlayer_for_loss, nn_weights)\n",
    "except:\n",
    "    print \"The problem occured. Weights were not saved\"\n",
    "else: print 'Weights were successfully saved to the file: ', file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* $ \\textbf{Visualizations}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='c'/>\n",
    "# Conclusions\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nbpresent": {
   "slides": {},
   "themes": {
    "default": "1e5df646-8a15-4399-a81f-a8ebdfdf69a2",
    "theme": {
     "1e5df646-8a15-4399-a81f-a8ebdfdf69a2": {
      "backgrounds": {
       "backgroundColor": {
        "background-color": "backgroundColor",
        "id": "backgroundColor"
       }
      },
      "id": "1e5df646-8a15-4399-a81f-a8ebdfdf69a2",
      "palette": {
       "backgroundColor": {
        "id": "backgroundColor",
        "rgb": [
         34,
         34,
         34
        ]
       },
       "headingColor": {
        "id": "headingColor",
        "rgb": [
         238,
         238,
         238
        ]
       },
       "linkColor": {
        "id": "linkColor",
        "rgb": [
         170,
         34,
         51
        ]
       },
       "mainColor": {
        "id": "mainColor",
        "rgb": [
         238,
         238,
         238
        ]
       }
      },
      "rules": {
       "a": {
        "color": "linkColor"
       },
       "h1": {
        "color": "headingColor",
        "font-family": "Ubuntu",
        "font-size": 7
       },
       "h2": {
        "color": "headingColor",
        "font-family": "Ubuntu",
        "font-size": 5
       },
       "h3": {
        "color": "headingColor",
        "font-family": "Ubuntu",
        "font-size": 3.75
       },
       "h4": {
        "color": "headingColor",
        "font-family": "Ubuntu",
        "font-size": 3
       },
       "h5": {
        "color": "headingColor",
        "font-family": "Ubuntu"
       },
       "h6": {
        "color": "headingColor",
        "font-family": "Ubuntu"
       },
       "h7": {
        "color": "headingColor",
        "font-family": "Ubuntu"
       },
       "li": {
        "color": "mainColor",
        "font-family": "Ubuntu",
        "font-size": 5
       },
       "p": {
        "color": "mainColor",
        "font-family": "Ubuntu",
        "font-size": 5
       }
      },
      "text-base": {
       "color": "mainColor",
       "font-family": "Ubuntu",
       "font-size": 5
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
