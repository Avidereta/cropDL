{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment template. \n",
    "## Note: \n",
    "template for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_name is allInoc_adadelta_8nfilters_debug\n"
     ]
    }
   ],
   "source": [
    "# description = {here could be a short description of the experiment}\n",
    "\n",
    "# specific name of the experiment\n",
    "eval_name = 'allInoc_adadelta_8nfilters_debug'\n",
    "\n",
    "if eval_name is None:\n",
    "    with open(path_to_dir+'eval_name.txt') as data_file:    \n",
    "        eval_name = json.load(data_file)\n",
    "print \"eval_name is\", eval_name "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The task is to predict number of lesions in the photo\n",
    "***\n",
    "### Content:\n",
    "* [Settings and experiment parameters](#sep)\n",
    "* [Load Data](#ld)\n",
    "* [Learning and visualizing results](#lav)\n",
    "* [Conclusions](#c)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Togle ON/OFF the raw code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "CODE WAS HIDDEN. TO TOGGLE ON/OFF THE RAW CODE, CLICK\n",
       "<a href=\"javascript:code_toggle()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "CODE WAS HIDDEN. TO TOGGLE ON/OFF THE RAW CODE, CLICK\n",
    "<a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"sep\"/>\n",
    "# Settings and experiment parameters\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=\"device=gpu2\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 2: Tesla K40m (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS=\"device=gpu2\"\n",
    "\n",
    "### Check theano ####\n",
    "import theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables and paths \n",
    "* $\\textbf{Add the main directory '.../code' to   sys.path}$. \n",
    "\n",
    "The following directory was added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/slowhome/makarova/columbia/code\n"
     ]
    }
   ],
   "source": [
    "#### Add the main dir to sys ####\n",
    "\n",
    "import os, sys\n",
    "\n",
    "parentdir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
    "print parentdir\n",
    "\n",
    "sys.path.insert(0, parentdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\textbf{Put your certain values or None}$ (then use run.ipynb to set them outside).\n",
    "\n",
    "Note: In case you put None, files with parameters should be in the same directory with this .ipynb file \n",
    "(else change path_to_dir by what ever you want)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_NN = True\n",
    "\n",
    "N_FILTERS = 4\n",
    "BATCH_SIZE = 20\n",
    "N_EPOCHS = 3000\n",
    "N_BATCHES_PER_EPOCH = 10\n",
    "N_BATCHES_PER_EPOCH_valid = 10\n",
    "PATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_FILTERS =  4\n",
      "BATCH_SIZE =  20\n",
      "N_EPOCHS =  3000\n",
      "PATCH SIZE =  256\n"
     ]
    }
   ],
   "source": [
    "# Read global params from files\n",
    "import json\n",
    "\n",
    "print \"N_FILTERS = \", N_FILTERS\n",
    "print \"BATCH_SIZE = \", BATCH_SIZE\n",
    "print \"N_EPOCHS = \", N_EPOCHS\n",
    "print \"PATCH SIZE = \", PATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/makarova/columbia/data/inoculated_1/gt_img_train_ellimg_small.txt\n",
      "/home/makarova/columbia/data/inoculated_1/gt_img_valid_ellimg_small.txt\n",
      "/home/makarova/columbia/data/inoculated_1/gt_img_test_ellimg_small.txt\n",
      "/home/makarova/columbia/code/results/\n"
     ]
    }
   ],
   "source": [
    "# txt files with paths to segmentation image and input image\n",
    "txt_train = '/home/makarova/columbia/data/inoculated_1/gt_img_train_ellimg_small.txt'\n",
    "txt_valid = '/home/makarova/columbia/data/inoculated_1/gt_img_valid_ellimg_small.txt'\n",
    "txt_test = '/home/makarova/columbia/data/inoculated_1/gt_img_test_ellimg_small.txt'\n",
    "\n",
    "from config import results_path\n",
    "# path to save the results for THIS experiment\n",
    "results_eval_path = results_path + eval_name + \"/\"\n",
    "\n",
    "print txt_train\n",
    "print txt_valid\n",
    "print txt_test\n",
    "\n",
    "print results_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### IMPORTS ####\n",
    "import matplotlib\n",
    "matplotlib.use('Pdf')\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='ld'/>\n",
    "# Load Data\n",
    "</a>\n",
    "\n",
    "* Load and visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_data(txt):\n",
    "    \n",
    "    imgs = []\n",
    "    imgs_gt = []\n",
    "    \n",
    "    with open(txt, 'r') as fin:\n",
    "        lines = fin.read().splitlines()\n",
    "    for line in lines:\n",
    "        imgs.append(line.split(' ')[1]) \n",
    "        imgs_gt.append(line.split(' ')[0])\n",
    "    \n",
    "    assert(len(imgs) == len(imgs_gt))\n",
    "    imgs.sort()\n",
    "    imgs_gt.sort()\n",
    "    \n",
    "    # images are 2000 by 3000 pixels each\n",
    "    img_size = (2000, 3000)\n",
    "    data = np.zeros((len(imgs), 3, img_size[0], img_size[1]), dtype=np.uint8)\n",
    "    target = np.zeros((len(imgs), 1,  img_size[0], img_size[1]), dtype=np.uint8)\n",
    "    \n",
    "    ctr = 0\n",
    "    for i, (im, gt_im) in enumerate(zip(imgs, imgs_gt)):\n",
    "        data[ctr] = plt.imread(im).transpose((2, 0, 1))\n",
    "        img = plt.imread(gt_im,0)\n",
    "        target[ctr, 0] = img/255.\n",
    "        ctr += 1\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = load_data(txt_train)\n",
    "X_valid, Y_valid = load_data(txt_valid)\n",
    "X_test, Y_test = load_data(txt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 3, 2000, 3000)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print Y_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    }
   ],
   "source": [
    "print X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 1, 2000, 3000)\n"
     ]
    }
   ],
   "source": [
    "print Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='lav'/>\n",
    "# Learning and Visualizing\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.generator import batch_generator, random_crop_generator, threaded_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\textbf{ Characteristics of input images and the input layer}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape (2000, 3000)\n",
      "Number of channels: 3\n",
      "Input layer shape: [20, 3, 256, 256]\n"
     ]
    }
   ],
   "source": [
    "#### PREPARE DATA FOR NN ####\n",
    "\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lasagne.layers import InputLayer\n",
    "\n",
    "nmb_channels, inp_shape = X_train[0].shape[0], X_train[0].shape[1:]\n",
    "print 'Image shape', inp_shape\n",
    "print \"Number of channels:\", nmb_channels\n",
    "\n",
    "X_inp = T.tensor4('X_inp')\n",
    "X_layer = InputLayer([BATCH_SIZE, nmb_channels, PATCH_SIZE, PATCH_SIZE], \\\n",
    "                     input_var=X_inp,name='input')\n",
    "\n",
    "print \"Input layer shape:\", X_layer.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from models.unet import uNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\textbf{ Characteristics of NN}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.net['deconv1'].shape, self.net['contr_4_2'].shape (20, 64, 32, 32) (20, 32, 32, 32)\n",
      "self.net['output_segmentation'] (20, 2, 256, 256)\n",
      "self.net['dimshuffle'] (2, 20, 256, 256)\n",
      "self.net['reshapeSeg'] (2, 1310720)\n",
      "self.net['dimshuffle2'] (1310720, 2)\n",
      "self.net['output_flattened'] (2, 1310720)\n",
      "(20, 2, 256, 256) (2, 1310720)\n"
     ]
    }
   ],
   "source": [
    "#### LOAD NN ####\n",
    "cnn = uNet(X_layer,n_filters=N_FILTERS,nmb_out_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total weights: 123030\n"
     ]
    }
   ],
   "source": [
    "### WEIGHTS sanity check ###\n",
    "total_weights = int(T.sum([T.prod(w.shape) for w in cnn.weights]).eval())\n",
    "print \"Total weights:\", total_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\textbf{Objective loss, updates, train and eval fuctions}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### GROUND TRUTH and CLASS_WEIGHTS theano vectors ####\n",
    "Y_gt = T.ivector('Target Y integer')\n",
    "weights = T.vector('Loss weights')\n",
    "ce,reg_l2, acc = cnn.get_loss_components(Y_gt, weights)\n",
    "loss = ce+reg_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax.0\n"
     ]
    }
   ],
   "source": [
    "prediction_train = cnn.pred_y\n",
    "print prediction_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "updates = lasagne.updates.adadelta(loss,cnn.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a convenience function to get the segmentation\n",
    "seg_output = lasagne.layers.get_output(cnn.outlayer_seg,X_inp)\n",
    "seg_output = seg_output.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_test = lasagne.layers.get_output(cnn.outlayer_for_loss, X_inp, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_func = theano.function([X_inp,Y_gt,weights], [ce,reg_l2,acc], updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### FOR DEBUG ####\n",
    "# from theano.compile.debugmode import DebugMode\n",
    "# theano.config.exception_verbosity='high'\n",
    "# T.cmp_sloppy=1\n",
    "# train_func = theano.function([X_inp,Y_gt], [loss, acc_train], updates=updates, mode=DebugMode(check_isfinite=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_func = theano.function([X_inp, Y_gt, weights], [ce,reg_l2,acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_segmentation = theano.function([X_inp], seg_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Note: Set weights for classes here ####\n",
    "lesion_weight = 1.\n",
    "nonlesion_weight = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\textbf{Train NN}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.persistence import *\n",
    "import time, datetime, pytz\n",
    "from utils.persistence import *\n",
    "from visualizers.metrics import Metrics\n",
    "metrics = Metrics()\n",
    "from datetime import datetime as dt\n",
    "\n",
    "def train_nn (N_EPOCHS):\n",
    "    \n",
    "    with open(logs_path, \"a+\") as logs:\n",
    "                cur_time = dt.now(pytz.timezone('US/Eastern')).time()\n",
    "                logs.write(\"\\n\\nEval {}, \\nCurrent time {} \\n\"\\\n",
    "               .format(eval_name, cur_time.strftime(\"%Y-%m-%d %H:%M\")))\n",
    "                \n",
    "    losses = []    \n",
    "    epoch = 1\n",
    "\n",
    "    t_start = time.time()\n",
    "    \n",
    "    for i in range(N_EPOCHS):\n",
    "        print \"epoch\", epoch\n",
    "        n_batches = 0\n",
    "        t0 = time.time()\n",
    "        for j in range(N_BATCHES_PER_EPOCH):\n",
    "            data, target = train_generator.next()\n",
    "            target_flat = target.flatten()\n",
    "            if (i==0 and j==0): print '0 {}, 1 {}'.format(np.sum(target==0), np.sum(target==1))\n",
    "            # make a binary vector of weights for target elements\n",
    "            weights_target = np.where(target_flat<0.5, nonlesion_weight, lesion_weight).astype(np.float32)\n",
    "            ce_i, reg_i, acc_i = train_func(data.astype(np.float32),target_flat,weights_target)   \n",
    "            print 'ce_i, reg_i, acc_i', np.round(ce_i,3), np.round(reg_i,3), np.round(acc_i,3)\n",
    "            loss_i = ce_i+reg_i\n",
    "            \n",
    "            metrics[\"train loss\"][epoch] = ce_i\n",
    "            metrics[\"train full objective\"][epoch] = loss_i\n",
    "            metrics[\"train reg\"][epoch] = reg_i\n",
    "            losses.append(loss_i)   \n",
    "            n_batches += 1\n",
    "            if n_batches > N_BATCHES_PER_EPOCH:\n",
    "                break\n",
    "\n",
    "        if epoch%10==0:\n",
    "            data, target = validation_generator.next()\n",
    "            target_flat = target.flatten()\n",
    "            weights_target = np.where(target_flat<0.5, nonlesion_weight, lesion_weight).astype(np.float32)\n",
    "            ce_i, reg_i, acc_i = eval_func(data.astype(np.float32), target_flat, weights_target)\n",
    "#             print 'eval: ce_i, reg_i, acc_i', ce_i, reg_i, acc_i\n",
    "            loss_i = ce_i+reg_i\n",
    "            \n",
    "            metrics[\"test loss\"][epoch] = ce_i\n",
    "            metrics[\"test full objective\"][epoch] = loss_i\n",
    "            metrics[\"test reg\"][epoch] = reg_i \n",
    "\n",
    "\n",
    "        if epoch%10==0:\n",
    "            print \"epoch:\",epoch\n",
    "            print 'mean loss for the last 10 epochs:', np.round(np.mean(losses[-10:]),3)\n",
    "            with open(logs_path, \"a+\") as logs:\n",
    "                cur_time = dt.now(pytz.timezone('US/Eastern'))\n",
    "                logs.write(\"\"\"\\nEpoch {}, \\nCurrent time {} \\nmean loss for the last 10 epochs:{}\"\"\"\\\n",
    "               .format(epoch,cur_time.strftime(\"%Y-%m-%d %H:%M\"), np.round(np.mean(losses[-10:]),3)))\n",
    "\n",
    "        if epoch%100==0:\n",
    "            # plot and save metrics\n",
    "            fig = plt.figure(figsize=[15,5])\n",
    "            path_save_plot = \"MetricsEpoch{}.png\".format(epoch)\n",
    "            metrics.plot(save=True, path_to_save= path_save_plot)\n",
    "            # weights snapshort\n",
    "            plt.close()\n",
    "            file_weights_path = eval_name + '_weights{}epoch'.format(epoch) + '.pickle'\n",
    "            save(cnn.outlayer_for_loss, file_weights_path)\n",
    "            \n",
    "            plot_some_results(validation_generator, test_gen, BATCH_SIZE, \n",
    "                              info=True, n_images=4,path_to_save='.')\n",
    "\n",
    "        epoch+=1\n",
    "        print 'time for epoch: {} mins'\\\n",
    "        .format(round((time.time() - t0)/60.0, 3))\n",
    "    print 'Overall time: {} mins'.format(round((time.time() - t_start)/60.0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_generator = random_crop_generator(batch_generator(X_train, Y_train, BATCH_SIZE), \n",
    "                                        info=True, crop_size=PATCH_SIZE)\n",
    "train_generator = threaded_generator(train_generator, num_cached=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtain images of the same size for validation\n",
    "validation_generator = random_crop_generator(batch_generator(X_valid, Y_valid, BATCH_SIZE), \n",
    "                                             info=True, crop_size=PATCH_SIZE)\n",
    "validation_generator = threaded_generator(validation_generator, num_cached=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_EPOCHS =  3000\n",
      "epoch 1\n",
      "0 1232132, 1 78588\n",
      "ce_i, reg_i, acc_i 0.886 0.004 0.879\n",
      "ce_i, reg_i, acc_i 0.735 0.004 0.76\n",
      "ce_i, reg_i, acc_i 0.745 0.004 0.292\n",
      "ce_i, reg_i, acc_i 0.726 0.004 0.303\n",
      "ce_i, reg_i, acc_i 1.241 0.004 0.521\n"
     ]
    }
   ],
   "source": [
    "#### TRAIN NN ####\n",
    "logs_path = './logs.txt'\n",
    "from utils.persistence import *\n",
    "import time\n",
    "\n",
    "print \"N_EPOCHS = \", N_EPOCHS\n",
    "nn_weights = results_eval_path + eval_name + \"_weights.pickle\"\n",
    "TRAIN_NN=True\n",
    "if TRAIN_NN:\n",
    "    train_nn(N_EPOCHS) \n",
    "else:\n",
    "    try:\n",
    "        a = load(cnn.outlayer_for_loss, nn_weights)\n",
    "    except:\n",
    "        print \"problem with weights loading, nn is being trained\"\n",
    "        train_nn(N_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\textbf{Save weights}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.persistence import *\n",
    "\n",
    "if not os.path.exists(results_eval_path):\n",
    "    os.makedirs(results_eval_path)\n",
    "    \n",
    "file_path = results_eval_path + eval_name + '_weights' + '.pickle'\n",
    "save(cnn.outlayer_for_loss, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### TEST SAVING ####\n",
    "try:\n",
    "    a = load(cnn.outlayer_for_loss, nn_weights)\n",
    "except:\n",
    "    print \"The problem occured. Weights were not saved\"\n",
    "else: print 'Weights were successfully saved to the file: ', file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* $ \\textbf{Visualizations}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_some_results(pred_fn, test_generator, BATCH_SIZE,path_to_save,  n_images=10, \n",
    "                    info = False, info_threshold=0.05):\n",
    "    \n",
    "    def plot(d,s,r):\n",
    "        fig = plt.figure(figsize=(12, 6))\n",
    "            \n",
    "        ax1 = fig.add_subplot(131)\n",
    "        ax1.imshow(d.transpose(1,2,0))\n",
    "        ax1.set_title('input')\n",
    "\n",
    "        ax2 = fig.add_subplot(132)\n",
    "        ax2.imshow(s[0])\n",
    "        ax2.set_title('gt')\n",
    "\n",
    "        ax3 = fig.add_subplot(133)\n",
    "        ax3.imshow(r)\n",
    "        ax3.set_title('prediction')\n",
    "\n",
    "        plt.savefig(path_to_save+\"{}.png\".format(fig_ctr))\n",
    "        plt.close()\n",
    "            \n",
    "    fig_ctr = 0\n",
    "    for data, seg in test_generator:\n",
    "        res = pred_fn(data)\n",
    "        for d, s, r in zip(data, seg, res):\n",
    "            print 'np.sum(s>0),np.sum(s==0), np.sum(r>0),np.sum(r==0)', \\\n",
    "            np.sum(s>0),np.sum(s==0), np.sum(r>0),np.sum(r==0)\n",
    "            if info:\n",
    "                info_percent = np.sum(s > 0)*1./ np.size(s.ravel())\n",
    "                if info_percent < info_threshold:\n",
    "                    pass\n",
    "                 \n",
    "                else: \n",
    "                    print 'info_percent', info_percent\n",
    "                    plot(d,s,r)\n",
    "                    fig_ctr += 1\n",
    "                    print 'done:', fig_ctr\n",
    "            else:\n",
    "                    plot(d,s,r)\n",
    "                    fig_ctr += 1\n",
    "                    print 'done:', fig_ctr\n",
    "        if fig_ctr > n_images:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create some png files showing (raw image, ground truth, prediction)\n",
    "test_gen = random_crop_generator(batch_generator(X_test, Y_test, BATCH_SIZE), PATCH_SIZE)\n",
    "path_to_save = os.path.join(results_eval_path + eval_name)\n",
    "print 'plots are saved to:', path_to_save\n",
    "plot_some_results(get_segmentation, test_gen, BATCH_SIZE, info=True, path_to_save=path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "files = [os.path.join(results_eval_path,f) for f in os.listdir(results_eval_path) if f.endswith('.png')][:30]\n",
    "print files\n",
    "\n",
    "for f in files:\n",
    "    plt.figure()\n",
    "    plt.imshow(plt.imread(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='c'/>\n",
    "# Conclusions\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
